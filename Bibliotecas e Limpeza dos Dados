Os dados são analisados por uma predição importada pela biblioteca *sklearn* e *tensorflow* para o treinamento da máquina:

_Foram utilizadas outras bibliotecas mais comuns como: para fazer os cálculos (numpy), para manipulação de dados (pandas) e para plotagem de gráficos após a análise (matplotlib)._

    import tensorflow as tf
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.model_selection import train_test_split
    import matplotlib.pyplot as plt

Fazemos alguns ajustes aos dados para que o modelo possa trabalhar sem dificuldades. Utilizamos algumas funções de pré-processamento, para limpeza desses dados: 

    df['timestamp'] = df['DataHora'].apply(lambda x: x.timestamp())

# Conversão de DataHora para *timestamp*.
# Normalização dos dados com *MinMaxScaler* para que todos os valores fiquem na mesma escala.

# Estrutura dos Dados
O conjunto de dados utilizado para treinamento e previsões inclui:

DataHora: Marca temporal das medições (ajustável conforme o período desejado).
Consumo de Energia: Consumo de energia simulado ou real.
Temperatura Externa: Temperatura externa simulada ou real.
Taxa de Produção: Taxa de produção da fábrica (ajustável conforme necessário).
Eficiência da Máquina: Eficiência das máquinas na produção (ajustável conforme o cenário).
Meta: A meta de produção (ajustável conforme a necessidade do projeto).

Os dados são pré-processados e normalizados para alimentar o modelo de rede neural.
